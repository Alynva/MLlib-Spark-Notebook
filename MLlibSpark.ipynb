{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xezl4Ox7CVqH"
      },
      "source": [
        "---\n",
        "# MLlib Spark\n",
        "\n",
        "## Aprendizado de Máquina no Apache Spark\n",
        "\n",
        "Alunos:\n",
        "\n",
        "\n",
        "*   **Alisson Nunes** (725862)\n",
        "*   **Lucas Mathaeus** (726561)\n",
        "*   **William Eugênio** (726601)\n",
        "\n",
        "Bacharelado em Ciência da Computação (BCC)<br>\n",
        "Departamento de Computação (DC)<br>\n",
        "Universidade Federal de São Carlos (UFSCar)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krASYLGNEisA"
      },
      "source": [
        "#  (1) Obtenção dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#instalando o módulo wget\n",
        "#%%capture\n",
        "%pip install -q wget\n",
        "%mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#baixando os dados das tabelas de dimensão do data mart Exame\n",
        "import wget\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/cristinaaguiar/dataMartExame/main/idade.csv\"\n",
        "wget.download(url, \"data/idade.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/cristinaaguiar/dataMartExame/main/data.csv\"\n",
        "wget.download(url, \"data/data.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/cristinaaguiar/dataMartExame/main/descreveExame.csv\"\n",
        "wget.download(url, \"data/descreveExame.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/cristinaaguiar/dataMartExame/main/hospital.csv\"\n",
        "wget.download(url, \"data/hospital.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/cristinaaguiar/dataMartExame/main/exame.csv\"\n",
        "wget.download(url, \"data/exame.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "O sistema n�o pode encontrar o caminho especificado.\n",
            "UsageError: Line magic function `%wget` not found.\n"
          ]
        }
      ],
      "source": [
        "#instalando os pacotes para o uso de Spark em Python\n",
        "# %%capture\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!rm spark-3.0.0-bin-hadoop2.7.tgz\n",
        "%pip install -q findspark\n",
        "%pip install -q pyspark==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#configurando as variaveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#instalando o pacote findspark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#definindo uma sessão Spark para usar o pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(remover ele chama o banco assim: \n",
        "\n",
        "#criando e exibindo o DataFrame em Spark para a tabela de dimensão idade\n",
        "idade = spark.read.csv(path=\"data/idade.csv\", header=True, sep=\",\")\n",
        "idade.show()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTW_jfxyFKoF"
      },
      "source": [
        "# (2) Instalação e Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWo_hkGuGyyr",
        "outputId": "70bb0056-e4e9-4ee1-d4ca-83a3389c65b1"
      },
      "outputs": [],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqf5REj-FOMp"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit (system)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "c41245681b0c5dfdc198064911b7c792a0421ee2cbedc4ec4c9079156fd03e41"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
